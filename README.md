# MULTIMODAL SENTIMENT ANALYSIS
Final project for the 2022 Postgraduate course on Artificial Intelligence with Deep Learning, UPC School, authored by **Alex Romero Honrubia**, **Alexandra Ab√≥s Ortega**, **Oriol Algaba Birba** and **Laia Gasparin Pedraza**. 

Advised by **Gerard **.

Table of Contents
=================

  * [INTRODUCTION AND MOTIVATION](#introduction-and-motivation)
  * [DATASET](#dataset)
  * [ARCHITECTURE AND RESULTS](#architecture-and-results)
	 * [Video](#video-arch)
	 * [Audio](#i3d)
	 * [Multimodal](#multimodal-network)
  * [HOW TO TRAIN THE MODEL](#how-to-train-the-model)
  * [Setting the environment](#setting-the-environment)
  * [Running training scripts](#running-training-scripts)
  * [HOW TO RUN THE PROGRAM - video_processor](#how-to-run-the-program---video_processor)
  * [Installation](#installation)
	 * [Install Docker](#install-docker)
	 * [Install docker-compose](#install-docker-compose)
	 * [Create your .env file](#create-your-env-file)
	 *
  * [HOW TO RUN THE PROGRAMvideo_capture](#how-to-run-the-program)
---
---

## INTRODUCTION AND MOTIVATION
Video conferencing is experimenting a huge growth since the pandemic accross all industries. Video conferencing is now involving extra features as it is becoming the new working environment as well as new channel to consume professional services. A key point of the communication is the sentiment associated with the message. 

Nowadays, there are videoconferencing applications that transcript the conversations. This is useful for real-time consumption, i.e. better understanding of different accents,  as a support for deafs or for conversational voicebots. This is also useful for post-processing of the meeting, to extract notes or to analyze the conversation, i.e. recruiting interview. The transcript of a conversation would be much more complete if associated with an emotion. 

Working, studying and sometimes meeting friends through the videoconferencing platforms made us think about this need. In addition, we were curious to learn how to combine video and audio in the same model and to deep dive on the transformer. 

## DATASET

## ARCHITECTURE AND RESULTS
### Video
### Audio
### Miltimodal
## How to Train the Model

## Settting the environment

python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt



